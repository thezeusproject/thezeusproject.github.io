### Project: KNN Classifier

<div class="progress-bar-container">
  <div class="progress-bar" style="width: 0%;"></div>
</div>

- [ ] **Task 1: Setup the environment**
  - [ ] Install Python and required libraries (NumPy, Matplotlib, scikit-learn).
  - [ ] Set up a virtual environment.
- [ ] **Task 2: Create or load a dataset**
  - [ ] Generate synthetic classification data or load a standard dataset (e.g., Iris).
  - [ ] Visualize the data using scatter plots (for 2D features).
- [ ] **Task 3: Implement KNN from scratch**
  - [ ] Write a distance function (Euclidean/Manhattan).
  - [ ] Implement the KNN prediction logic.
  - [ ] Add voting mechanism for classification.
- [ ] **Task 4: Evaluate the model**
  - [ ] Split data into training and test sets.
  - [ ] Calculate accuracy metrics.
  - [ ] Implement cross-validation.
- [ ] **Task 5: Visualize decision boundaries**
  - [ ] Plot decision regions for different K values.
  - [ ] Visualize how boundaries change with K.

---

### Project: KNN Hyperparameter Tuning
<div class="progress-bar-container">
  <div class="progress-bar" style="width: 0%;"></div>
</div>

- [ ] **Task 1: Explore K values**
  - [ ] Test KNN with different K values (1 to 20).
  - [ ] Record accuracy for each K.
- [ ] **Task 2: Compare distance metrics**
  - [ ] Implement with Euclidean, Manhattan, and Minkowski distances.
  - [ ] Compare their effects on accuracy.
- [ ] **Task 3: Weighted KNN**
  - [ ] Implement distance-weighted voting.
  - [ ] Compare with standard KNN.
- [ ] **Task 4: Plot learning curves**
  - [ ] Visualize accuracy vs. K value.
  - [ ] Plot training vs validation accuracy.